{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Feature Importance Methods for Scientific Inference — SOLUTIONS\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Setup\n\nRun all cells in this section first."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "!pip install fippy -q"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.rcParams.update({\n    'font.size':        14,\n    'axes.titlesize':   16,\n    'axes.labelsize':   14,\n    'xtick.labelsize':  13,\n    'ytick.labelsize':  13,\n})"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Data Generating Process\n\n$$X_1 \\sim \\mathcal{N}(0,1), \\quad X_3 \\sim \\mathcal{N}(0,1), \\quad X_5 \\sim \\mathcal{N}(0,1) \\quad \\text{(mutually independent)}$$\n$$X_2 = 0.999\\,X_1 + \\sqrt{1-0.999^2}\\,\\varepsilon_2, \\qquad X_4 = 0.999\\,X_3 + \\sqrt{1-0.999^2}\\,\\varepsilon_4$$\n$$Y = 5\\,X_1 + \\varepsilon_Y, \\quad \\varepsilon_Y \\sim \\mathcal{N}(0,1)$$\n\nOnly $X_1$ causes $Y$. $X_2$ is a noisy copy of $X_1$. $X_3$/$X_4$ are a correlated but irrelevant pair. $X_5$ is purely irrelevant."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def generate_data(n=1500, seed=83):\n    rng = np.random.RandomState(seed)\n    x1 = rng.normal(0, 1, n)\n    x2 = 0.999 * x1 + np.sqrt(1 - 0.999**2) * rng.normal(0, 1, n)\n    x3 = rng.normal(0, 1, n)\n    x4 = 0.999 * x3 + np.sqrt(1 - 0.999**2) * rng.normal(0, 1, n)\n    y  = 5 * x1 + rng.normal(0, 1, n)\n    x5 = rng.normal(0, 1, n)\n    X  = np.column_stack([x1, x2, x3, x4, x5])\n    return X, y\n\nX, y = generate_data()\nfeature_names = [\"X1\", \"X2\", \"X3\", \"X4\", \"X5\"]"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Model\n\nOLS on 1000 training observations, evaluated on 500 test observations."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "n_train = 1000\nX_train, X_test = X[:n_train], X[n_train:]\ny_train, y_test = y[:n_train], y[n_train:]\n\nmodel = LinearRegression().fit(X_train, y_train)\nprint(f\"Test R\\u00b2: {model.score(X_test, y_test):.3f}\")\nprint(f\"Coefficients: {np.round(model.coef_, 2)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### fippy setup\n\nThe **Gaussian sampler** estimates $P(X_j \\mid X_{-j})$ in closed form under the multivariate normal assumption."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from fippy.explainers import Explainer\nfrom fippy.samplers import GaussianSampler\n\nX_train_df = pd.DataFrame(X_train, columns=feature_names)\nX_test_df  = pd.DataFrame(X_test,  columns=feature_names)\ny_train_s  = pd.Series(y_train, name='y')\ny_test_s   = pd.Series(y_test,  name='y')\n\nsampler   = GaussianSampler(X_train_df)\nexplainer = Explainer(model.predict, X_train_df,\n                      loss=mean_squared_error, sampler=sampler)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Solution 2: PFI — Implementation and Why It Misleads\n\n**PFI** permutes feature $j$, breaking its association with all other variables, and measures the\nresulting increase in loss:\n\n$$\\text{PFI}_j = \\mathbb{E}[L(Y, \\hat{f}(\\tilde{X}_j, X_{-j}))] - \\mathbb{E}[L(Y, \\hat{f}(X))], \\quad \\tilde{X}_j \\perp X_{-j}$$"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def my_pfi(model, X, y, feature_idx, n_repeats=50, seed=42):\n    \"\"\"Permutation Feature Importance for a single feature.\"\"\"\n    rng = np.random.RandomState(seed)\n    baseline_mse = mean_squared_error(y, model.predict(X))\n\n    perturbed_mses = []\n    for _ in range(n_repeats):\n        X_perm = X.copy()\n        X_perm[:, feature_idx] = rng.permutation(X[:, feature_idx])\n        perturbed_mses.append(mean_squared_error(y, model.predict(X_perm)))\n\n    return np.mean(perturbed_mses) - baseline_mse\n\n\npfi_scores = [my_pfi(model, X_test, y_test, j) for j in range(len(feature_names))]\nfor name, score in zip(feature_names, pfi_scores):\n    print(f\"PFI({name}): {score:.4f}\")\n\nplt.figure(figsize=(6, 4))\nplt.barh(feature_names[::-1], pfi_scores[::-1], color='grey', edgecolor='black', linewidth=0.5)\nplt.xlabel(\"PFI (increase in MSE)\")\nplt.title(\"Permutation Feature Importance\")\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Scatterplot: (X3, X4) before and after permuting X3\nrng = np.random.RandomState(42)\nX_perm = X_test.copy()\nX_perm[:, 2] = rng.permutation(X_test[:, 2])\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 4))\naxes[0].scatter(X_test[:, 2], X_test[:, 3], alpha=0.3, s=10, color='grey')\naxes[0].set(xlabel=\"$X_3$\", ylabel=\"$X_4$\", title=\"Original: $(X_3, X_4)$\",\n            xlim=(-4,4), ylim=(-4,4))\naxes[1].scatter(X_perm[:, 2], X_perm[:, 3], alpha=0.3, s=10, color='grey')\naxes[1].set(xlabel=r\"$\\tilde{X}_3$ (permuted)\", ylabel=\"$X_4$\",\n            title=\"After permuting $X_3$\", xlim=(-4,4), ylim=(-4,4))\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Interpretation\n\n**PFI values are high for all features except $X_5$** — including $X_3$ and $X_4$, which are\ncompletely independent of $Y$.\n\n**Why?** The fitted coefficients are $\\hat{\\beta} \\approx [3.11, 1.88, -2.11, 2.17, 0.02]$.\nBecause $X_3 \\approx X_4$ ($\\rho = 0.999$), OLS assigns them large opposing coefficients that\nnearly cancel in the original data. Permuting $X_3$ destroys this cancellation — the model's\npredictions blow up, and PFI records a large error increase.\n\nThe scatterplot makes this visible: the original $(X_3, X_4)$ data lies on a tight diagonal.\nAfter permuting $X_3$, the cloud becomes circular — these out-of-distribution combinations\nnever appeared during training.\n\n**Key takeaway:** PFI measures *model reliance*, not association with $Y$.\n\n| Conclusion | PFI $\\neq$ 0 | PFI $= 0$ |\n|---|---|---|\n| Model uses feature | ✅ | ❓ |\n| Feature is predictive of $Y$ | ❓ | ❓ |\n| Feature is causally relevant | ❓ | ❓ |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Solution 3: Conditional Feature Importance (CFI)\n\nCFI replaces the permutation sampler with sampling from $P(X_j \\mid X_{-j})$, preserving\nthe correlations between features while still breaking the direct $X_j$–$Y$ link:\n\n$$\\text{CFI}_j = \\mathbb{E}[L(Y, \\hat{f}(\\tilde{X}_j, X_{-j}))] - \\mathbb{E}[L(Y, \\hat{f}(X))], \\quad \\tilde{X}_j \\sim P(X_j \\mid X_{-j})$$\n\nThe Gaussian sampler estimates this conditional distribution in closed form."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "ex_cfi = explainer.cfi(X_test_df, y_test_s, nr_runs=10)\nex_cfi.hbarplot()\nplt.show()\n\nmeans, stds = ex_cfi.fi_means_stds()\nprint(\"CFI scores:\")\nfor feat, m, s in zip(feature_names, means, stds):\n    print(f\"  {feat}: {m:.4f} ± {s:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Interpretation\n\n**Only $X_1$ receives a non-zero CFI score.** All others are $\\approx 0$.\n\nWhy the conditional sampler fixes the problem:\n- **$X_2$**: $\\tilde{X}_2 \\sim P(X_2 \\mid X_1, X_3, X_4, X_5) \\approx X_1$, so the model's\n  prediction barely changes. CFI $\\approx 0$ — $X_2$ carries no information about $Y$ *beyond\n  what $X_1$ already provides*.\n- **$X_3, X_4$**: $\\tilde{X}_3 \\sim P(X_3 \\mid X_4, \\ldots)$ preserves $\\rho(X_3, X_4) = 0.999$,\n  so the large opposing coefficients still cancel. CFI $\\approx 0$ — they are irrelevant to $Y$.\n- **$X_5$**: independent of everything; resampling changes nothing. CFI $\\approx 0$.\n- **$X_1$**: once $X_1$ is conditionally resampled, its strong direct effect on $Y$ is broken.\n  CFI is large and positive.\n\n**CFI $\\neq 0$ implies conditional dependence:** $X_j \\not\\perp\\!\\!\\!\\perp Y \\mid X_{-j}$.\n\n| Conclusion | CFI $\\neq$ 0 | CFI $= 0$ |\n|---|---|---|\n| Model uses feature | ✅ | ❓ |\n| Pairwise association with $Y$ | ❓ | ❓ |\n| Conditional association with $Y$ | ✅ | ❓ |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Solution 4: Leave-One-Covariate-Out (LOCO)\n\nLOCO measures the **drop in explained variance** when a feature is removed from the full model,\nwith the missing feature marginalised out via its conditional distribution:\n\n$$\\text{LOCO}_j = v(\\{1,\\ldots,p\\}) - v(\\{1,\\ldots,p\\} \\setminus \\{j\\})$$\n\nwhere the conditional SAGE value function is:\n\n$$v(S) = \\mathbb{E}[(Y - \\mathbb{E}[f(X)])^2] - \\mathbb{E}[(Y - \\mathbb{E}[f(X)\\mid X_S])^2]$$\n\n$v(N) \\approx \\text{Var}(Y) \\cdot R^2$, so expressing LOCO as a fraction of $v(N)$ gives\neach feature's **share of the model's $R^2$**."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "N = feature_names\n\n# v(N) – explained variance of the full model\nex_vN = explainer.csagevf(S=list(N), X_eval=X_test_df, y_eval=y_test_s)\nmeans_N, _ = ex_vN.fi_means_stds()\nv_N = float(np.array(means_N).flatten()[0])\nprint(f\"v(all features) = {v_N:.4f}  [≈ Var(Y)·R²]\\n\")\n\n# LOCO = v(N) - v(N\\{j}) for every j, computed in one call\nex_loco = explainer.csagevfs(X_test_df, y_test_s, C='remainder')\nloco_means, loco_stds = ex_loco.fi_means_stds()\nloco_scores = dict(zip(feature_names, loco_means))\nfor feat, m in loco_scores.items():\n    print(f\"LOCO({feat}): {m:.4f}  ({100 * m / v_N:.1f}% of explained variance)\")\n\npct = [100 * loco_scores[f] / v_N for f in N]\nplt.figure(figsize=(6, 4))\nplt.barh(N[::-1], pct[::-1], color='grey', edgecolor='black', linewidth=0.5)\nplt.xlabel(\"Share of explained variance (%)\")\nplt.title(\"LOCO (conditional marginalization)\")\nplt.axvline(0, color='black', linewidth=0.8)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Interpretation\n\n**$X_1$ accounts for essentially all of the model's explained variance.**\nAll other features contribute $\\approx 0\\%$.\n\nThe logic for each feature:\n- **$X_1$**: removing it (and marginalising via $P(X_1 \\mid X_{-1})$) collapses predictions\n  to a near-constant, since no other feature carries information about $Y$. LOCO $\\approx R^2 \\cdot \\text{Var}(Y)$.\n- **$X_2$**: $P(X_2 \\mid X_1, X_3, X_4, X_5) \\approx X_1$, so the model's restricted prediction\n  $\\mathbb{E}[f(X) \\mid X_{-2}]$ is virtually identical to the full prediction. LOCO $\\approx 0$.\n- **$X_3, X_4$**: same argument — conditional distribution preserves the correlation, so the\n  opposing coefficients still cancel in the restricted model. LOCO $\\approx 0$.\n- **$X_5$**: near-zero coefficient, purely irrelevant. LOCO $\\approx 0$.\n\n**Comparison of the three methods:**\n\n| | PFI | CFI | LOCO |\n|---|---|---|---|\n| Model uses feature | ✅ iff $\\neq 0$ | ✅ iff $\\neq 0$ | ✅ iff $\\neq 0$ |\n| Pairwise assoc. $X_j \\not\\perp Y$ | ❓ | ❓ | ❓ |\n| Conditional assoc. $X_j \\not\\perp Y \\mid X_{-j}$ | ❓ | ✅ iff $\\neq 0$ | ✅ iff $\\neq 0$ |\n| Magnitude = share of explained variance | ❌ | ❌ | ✅ |\n\nLOCO is the only method here that gives an **interpretable magnitude**: its value directly equals\nthe reduction in $\\text{Var}(\\mathbb{E}[Y \\mid X_D])$ when feature $j$ is removed — the\nstandard definition of explained variance contribution."
  }
 ]
}