{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Feature Importance Methods for Scientific Inference\n\nIn these exercises you will:\n\n1. *(Lecture)* Interpret the pre-computed PFI plot and discuss why it can mislead\n2. Implement **Permutation Feature Importance (PFI)** yourself and visualise the out-of-distribution problem\n3. Compute **Conditional Feature Importance (CFI)** using the `fippy` package\n4. Compute **Leave-One-Covariate-Out (LOCO)** importance and interpret it in terms of explained variance\n5. Compute **Global Mean Absolute SHAP** values using KernelSHAP\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run all cells in this section before starting the exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "!pip install git+https://github.com/gcskoenig/fippy.git -q\n!pip install shap -q"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Per-observation squared error required by fippy for confidence interval computation\ndef square_error(y_true, y_pred):\n    return (np.array(y_true) - np.array(y_pred)) ** 2\n\nplt.rcParams.update({\n    'font.size':        14,\n    'axes.titlesize':   16,\n    'axes.labelsize':   14,\n    'xtick.labelsize':  13,\n    'ytick.labelsize':  13,\n})"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "We generate a dataset with 5 features and a continuous target variable $Y$.\n",
    "**The data-generating process is hidden for now.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n=1500, seed=83):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    x1 = rng.normal(0, 1, n)\n",
    "    x2 = 0.999 * x1 + np.sqrt(1 - 0.999**2) * rng.normal(0, 1, n)\n",
    "    x3 = rng.normal(0, 1, n)\n",
    "    x4 = 0.999 * x3 + np.sqrt(1 - 0.999**2) * rng.normal(0, 1, n)\n",
    "    y  = 5 * x1 + rng.normal(0, 1, n)\n",
    "    x5 = rng.normal(0, 1, n)\n",
    "    X  = np.column_stack([x1, x2, x3, x4, x5])\n",
    "    return X, y\n",
    "\n",
    "X, y = generate_data()\n",
    "feature_names = [\"X1\", \"X2\", \"X3\", \"X4\", \"X5\"]\n",
    "print(f\"Dataset: {X.shape}, features: {feature_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "We train an OLS linear regression on 1000 training observations and evaluate on 500 held-out test observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 1000\n",
    "X_train, X_test = X[:n_train], X[n_train:]\n",
    "y_train, y_test = y[:n_train], y[n_train:]\n",
    "\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "r2  = model.score(X_test, y_test)\n",
    "print(f\"Test R\\u00b2: {r2:.3f}\")\n",
    "print(f\"Coefficients: {np.round(model.coef_, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fippy setup\n",
    "\n",
    "We use the [`fippy`](https://github.com/gcskoenig/fippy) package for Exercises 3 and 4.\n",
    "The **Gaussian sampler** estimates the conditional distribution $P(X_j \\mid X_{-j})$ in closed form\n",
    "using the multivariate normal assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from fippy.explainers import Explainer\nfrom fippy.samplers import GaussianSampler\n\n# fippy requires pandas DataFrames\nX_train_df = pd.DataFrame(X_train, columns=feature_names)\nX_test_df  = pd.DataFrame(X_test,  columns=feature_names)\ny_train_s  = pd.Series(y_train, name='y')\ny_test_s   = pd.Series(y_test,  name='y')\n\nsampler   = GaussianSampler(X_train_df)\nexplainer = Explainer(model.predict, X_train_df,\n                      loss=square_error, sampler=sampler)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exercise 2: Implement PFI and Understand Why It Can Mislead\n",
    "\n",
    "Now we reveal the true data-generating process:\n",
    "\n",
    "$$X_1 \\sim \\mathcal{N}(0,1), \\quad X_3 \\sim \\mathcal{N}(0,1), \\quad X_5 \\sim \\mathcal{N}(0,1) \\quad \\text{(mutually independent)}$$\n",
    "$$X_2 = 0.999\\,X_1 + \\varepsilon_2, \\qquad X_4 = 0.999\\,X_3 + \\varepsilon_4$$\n",
    "$$Y = 5\\,X_1 + \\varepsilon_Y \\qquad \\Rightarrow \\text{only } X_1 \\text{ causes } Y$$\n",
    "\n",
    "The fitted model is $\\hat{f}(X) = 3.11\\,X_1 + 1.88\\,X_2 - 2.11\\,X_3 + 2.17\\,X_4 + 0.02\\,X_5$.\n",
    "\n",
    "**Tasks**\n",
    "\n",
    "1. Complete `my_pfi` below — the only missing piece is the permutation of one column.\n",
    "2. Create scatterplots of $(X_3, X_4)$ before and after permuting $X_3$.\n",
    "3. Explain why PFI assigns high importance to $X_3$ and $X_4$ even though they are independent of $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pfi(model, X, y, feature_idx, n_repeats=50, seed=42):\n",
    "    \"\"\"\n",
    "    Permutation Feature Importance for a single feature.\n",
    "\n",
    "    PFI_j = mean_r [ L(y, f(X_perm_r)) ] - L(y, f(X))\n",
    "\n",
    "    where X_perm_r is X with column feature_idx randomly permuted.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    baseline_mse = mean_squared_error(y, model.predict(X))\n",
    "\n",
    "    perturbed_mses = []\n",
    "    for _ in range(n_repeats):\n",
    "        X_perm = X.copy()\n",
    "        # ── YOUR CODE HERE ──────────────────────────────────────────\n",
    "        # Permute column feature_idx of X_perm using rng.permutation()\n",
    "\n",
    "\n",
    "        # ────────────────────────────────────────────────────────────\n",
    "        perturbed_mses.append(mean_squared_error(y, model.predict(X_perm)))\n",
    "\n",
    "    return np.mean(perturbed_mses) - baseline_mse\n",
    "\n",
    "\n",
    "# Compute and plot PFI for all features\n",
    "pfi_scores = [my_pfi(model, X_test, y_test, j) for j in range(len(feature_names))]\n",
    "for name, score in zip(feature_names, pfi_scores):\n",
    "    print(f\"PFI({name}): {score:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.barh(feature_names[::-1], pfi_scores[::-1], color='grey', edgecolor='black', linewidth=0.5)\n",
    "plt.xlabel(\"PFI (increase in MSE)\")\n",
    "plt.title(\"Permutation Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot: X3 vs X4 before and after permuting X3\n",
    "rng = np.random.RandomState(42)\n",
    "X_perm = X_test.copy()\n",
    "# ── YOUR CODE HERE: permute column 2 (X3) of X_perm ────────────────────────\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# ── YOUR CODE HERE: scatter X_test[:,2] vs X_test[:,3] on axes[0] ───────────\n",
    "\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "axes[0].set(xlabel=\"$X_3$\", ylabel=\"$X_4$\", title=\"Original: $(X_3, X_4)$\",\n",
    "            xlim=(-4,4), ylim=(-4,4))\n",
    "\n",
    "# ── YOUR CODE HERE: scatter X_perm[:,2] vs X_perm[:,3] on axes[1] ───────────\n",
    "\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "axes[1].set(xlabel=r\"$\\tilde{X}_3$ (permuted)\", ylabel=\"$X_4$\",\n",
    "            title=\"After permuting $X_3$\", xlim=(-4,4), ylim=(-4,4))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your explanation:**\n",
    "\n",
    "- What do you notice in the scatterplots?\n",
    "  - *Your answer here*\n",
    "\n",
    "- Why does PFI assign high importance to $X_3$ and $X_4$?\n",
    "  - *Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exercise 3: Conditional Feature Importance (CFI)\n",
    "\n",
    "Instead of breaking all dependencies (permutation sampler), CFI resamples $X_j$ from\n",
    "$P(X_j \\mid X_{-j})$, preserving the feature correlations.\n",
    "\n",
    "$$\\text{CFI}_j = \\mathbb{E}[L(Y, \\hat{f}(\\tilde{X}_j, X_{-j}))] - \\mathbb{E}[L(Y, \\hat{f}(X))], \\quad \\tilde{X}_j \\sim P(X_j \\mid X_{-j})$$\n",
    "\n",
    "We use `fippy`'s `GaussianSampler` to estimate the conditional distribution in closed form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Conditional Feature Importance via fippy\nex_cfi = explainer.cfi(X_test_df, y_test_s, nr_runs=10)\nex_cfi.hbarplot()\nplt.show()\n\nscores_agg = ex_cfi.scores.groupby('sample').mean()\nmeans = scores_agg.mean()\nstds  = scores_agg.std()\nprint(\"\\nCFI scores:\")\nfor feat in feature_names:\n    print(f\"  {feat}: {means[feat]:.4f} ± {stds[feat]:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "- How do CFI scores differ from PFI? Why?\n",
    "  - *Your answer here*\n",
    "\n",
    "- Which features receive non-zero CFI, and why?\n",
    "  - *Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exercise 4: Leave-One-Covariate-Out (LOCO)\n",
    "\n",
    "LOCO measures how much the model's **explained variance** drops when a feature is removed entirely.\n",
    "\n",
    "Using the conditional SAGE value function $v(S)$ — which quantifies the explained variance\n",
    "when only features $S$ are available:\n",
    "\n",
    "$$v(S) = \\mathbb{E}[(Y - \\mathbb{E}[f(X)])^2] - \\mathbb{E}[(Y - \\mathbb{E}[f(X)\\mid X_S])^2]$$\n",
    "\n",
    "LOCO is:\n",
    "$$\\text{LOCO}_j = v(\\{1,\\ldots,p\\}) - v(\\{1,\\ldots,p\\} \\setminus \\{j\\})$$\n",
    "\n",
    "We compute all leave-one-out values at once using `fippy`'s `csagevfs` method with `C='remainder'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "N = feature_names  # full coalition\n\n# v(N) on training and test data\nex_vN_train = explainer.csagevf(S=list(N), X_eval=X_train_df, y_eval=y_train_s)\nv_N_train = float(ex_vN_train.scores.groupby('sample').mean().mean().iloc[0])\nex_vN_test  = explainer.csagevf(S=list(N), X_eval=X_test_df,  y_eval=y_test_s)\nv_N_test  = float(ex_vN_test.scores.groupby('sample').mean().mean().iloc[0])\nprint(f\"v(N) train = {v_N_train:.4f},  v(N) test = {v_N_test:.4f}\\n\")\n\n# LOCO = v(N) - v(N\\{j}) for every j; nr_runs repetitions to capture variability\nex_loco_train = explainer.csagevfs(X_train_df, y_train_s, C='remainder', nr_runs=10)\nex_loco_test  = explainer.csagevfs(X_test_df,  y_test_s,  C='remainder', nr_runs=10)\n\ndef loco_stats(ex_loco, v_N, label):\n    agg   = ex_loco.scores.groupby('sample').mean()\n    means, stds = agg.mean(), agg.std()\n    print(f\"LOCO ({label}):\")\n    for feat in feature_names:\n        m, s = means[feat], stds[feat]\n        print(f\"  {feat}: {m:.4f} ± {s:.4f}  ({100 * m / v_N:.1f}%)\")\n    print()\n    return means, stds\n\nmeans_train, stds_train = loco_stats(ex_loco_train, v_N_train, \"train\")\nmeans_test,  stds_test  = loco_stats(ex_loco_test,  v_N_test,  \"test\")\n\n# Grouped horizontal bar plot (% of each split's explained variance)\npct_tr = [100 * means_train[f] / v_N_train for f in N]\npct_te = [100 * means_test[f]  / v_N_test  for f in N]\nerr_tr = [100 * stds_train[f]  / v_N_train for f in N]\nerr_te = [100 * stds_test[f]   / v_N_test  for f in N]\n\ny_pos  = np.arange(len(N))\nheight = 0.35\nfig, ax = plt.subplots(figsize=(7, 4))\nax.barh(y_pos + height/2, pct_tr[::-1], height, xerr=err_tr[::-1],\n        label='Train', color='steelblue', edgecolor='black', linewidth=0.5,\n        capsize=4, error_kw={'elinewidth': 1.5, 'capthick': 1.5})\nax.barh(y_pos - height/2, pct_te[::-1], height, xerr=err_te[::-1],\n        label='Test',  color='grey',      edgecolor='black', linewidth=0.5,\n        capsize=4, error_kw={'elinewidth': 1.5, 'capthick': 1.5})\nax.set_yticks(y_pos)\nax.set_yticklabels(N[::-1])\nax.axvline(0, color='black', linewidth=0.8)\nax.set_xlabel(\"Share of explained variance (%)\")\nax.set_title(\"LOCO (conditional marginalization)\")\nax.legend()\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Interpretation:**\n\n- Which features have non-zero LOCO on training vs. test data, and how do the scores differ?\n  - *Your answer here*\n\n- Some features show a positive LOCO on training data but a negative LOCO on test data. What does a negative LOCO mean, and why might this happen?\n  - *Your answer here*\n\n- How do LOCO scores differ from CFI, and what additional information do they provide?\n  - *Your answer here*"
  },
  {
   "cell_type": "markdown",
   "id": "eoijwuzo5g",
   "source": "---\n\n# Exercise 5: Global Feature Importance with KernelSHAP\n\nKernelSHAP estimates Shapley values — a game-theoretic attribution of each feature's\ncontribution to the model output — by fitting a weighted linear model over coalition samples.\nThe global importance of feature $j$ is the mean absolute SHAP value across test observations:\n\n$$\\text{MeanSHAP}_j = \\frac{1}{n}\\sum_{i=1}^{n} |\\phi_j^{(i)}|$$\n\n**Tasks**\n\n1. Run the cell below and compare the KernelSHAP ranking with PFI, CFI, and LOCO.\n2. How does KernelSHAP handle the correlated features $X_3$ and $X_4$?",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "8wfhd3ia7zy",
   "source": "import shap\n\n# Use 100 random background samples for efficiency\nbackground = shap.sample(X_train_df, 100, random_state=42)\nshap_explainer = shap.KernelExplainer(model.predict, background)\n\nshap_values_train = shap_explainer.shap_values(X_train_df)\nshap_values_test  = shap_explainer.shap_values(X_test_df)\n\nmean_abs_train = np.abs(shap_values_train).mean(axis=0)\nmean_abs_test  = np.abs(shap_values_test).mean(axis=0)\n\nprint(\"Mean |SHAP| values:\")\nfor name, tr, te in zip(feature_names, mean_abs_train, mean_abs_test):\n    print(f\"  {name}: train={tr:.4f}  test={te:.4f}\")\n\nfig, axes = plt.subplots(1, 2, figsize=(11, 4), sharey=True)\nfor ax, vals, title in zip(axes,\n                            [mean_abs_train, mean_abs_test],\n                            [\"KernelSHAP — Train\", \"KernelSHAP — Test\"]):\n    ax.barh(feature_names[::-1], vals[::-1], color='grey', edgecolor='black', linewidth=0.5)\n    ax.set_xlabel(\"Mean |SHAP value|\")\n    ax.set_title(title)\naxes[0].set_ylabel(\"Feature\")\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "z20q6ng9v9",
   "source": "**Interpretation:**\n\n- How does the KernelSHAP ranking compare to PFI, CFI, and LOCO?\n  - *Your answer here*\n\n- How does KernelSHAP distribute importance between the correlated pair $(X_3, X_4)$?\n  - *Your answer here*",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}